[model]
batch_size = 4
continue_train = false
epochs = 1
memory_optimization = true
memory_swap = false
memory_swap_lookahead = 0
memory_swap_path = .
model_tensor_type = FP32-FP32
#save_path = yolov2.bin
tensor_format = NCHW
type = NeuralNetwork

[optimizer]
beta1 = 0.9
beta2 = 0.999
epsilon = 1e-08
learning_rate = 0.001000
torch_ref = true
type = adam

[input0]
input_shape = 1:3:416:416
name = input0
normalization = false
standardization = false
trainable = true
type = input

[conv1/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 32
input_layers = input0(0)
kernel_size = 3,3
name = conv1/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv1/a2]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv1/a1(0)
momentum = 0.900000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv1/a2
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv1/a2/activation_realized]
activation = leaky_relu
input_layers = conv1/a2(0)
name = conv1/a2/activation_realized
trainable = true
type = activation

[conv1]
input_layers = conv1/a2/activation_realized(0)
name = conv1
padding = valid
pool_size = 2,2
pooling = max
stride = 2,2
trainable = true
type = pooling2d

[conv2/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 64
input_layers = conv1(0)
kernel_size = 3,3
name = conv2/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv2/a2]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv2/a1(0)
momentum = 0.900000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv2/a2
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv2/a2/activation_realized]
activation = leaky_relu
input_layers = conv2/a2(0)
name = conv2/a2/activation_realized
trainable = true
type = activation

[conv2]
input_layers = conv2/a2/activation_realized(0)
name = conv2
padding = valid
pool_size = 2,2
pooling = max
stride = 2,2
trainable = true
type = pooling2d

[conv3/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 128
input_layers = conv2(0)
kernel_size = 3,3
name = conv3/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv3]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv3/a1(0)
momentum = 0.900000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv3
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv3/activation_realized]
activation = leaky_relu
input_layers = conv3(0)
name = conv3/activation_realized
trainable = true
type = activation

[conv4/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 64
input_layers = conv3/activation_realized(0)
kernel_size = 1,1
name = conv4/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv4]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv4/a1(0)
momentum = 0.900000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv4
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv4/activation_realized]
activation = leaky_relu
input_layers = conv4(0)
name = conv4/activation_realized
trainable = true
type = activation

[conv5/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 128
input_layers = conv4/activation_realized(0)
kernel_size = 3,3
name = conv5/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv5/a2]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv5/a1(0)
momentum = 0.900000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv5/a2
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv5/a2/activation_realized]
activation = leaky_relu
input_layers = conv5/a2(0)
name = conv5/a2/activation_realized
trainable = true
type = activation

[conv5]
input_layers = conv5/a2/activation_realized(0)
name = conv5
padding = valid
pool_size = 2,2
pooling = max
stride = 2,2
trainable = true
type = pooling2d

[conv6/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 256
input_layers = conv5(0)
kernel_size = 3,3
name = conv6/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv6]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv6/a1(0)
momentum = 0.900000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv6
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv6/activation_realized]
activation = leaky_relu
input_layers = conv6(0)
name = conv6/activation_realized
trainable = true
type = activation

[conv7/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 128
input_layers = conv6/activation_realized(0)
kernel_size = 1,1
name = conv7/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv7]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv7/a1(0)
momentum = 0.900000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv7
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv7/activation_realized]
activation = leaky_relu
input_layers = conv7(0)
name = conv7/activation_realized
trainable = true
type = activation

[conv8/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 256
input_layers = conv7/activation_realized(0)
kernel_size = 3,3
name = conv8/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv8/a2]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv8/a1(0)
momentum = 0.900000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv8/a2
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv8/a2/activation_realized]
activation = leaky_relu
input_layers = conv8/a2(0)
name = conv8/a2/activation_realized
trainable = true
type = activation

[conv8]
input_layers = conv8/a2/activation_realized(0)
name = conv8
padding = valid
pool_size = 2,2
pooling = max
stride = 2,2
trainable = true
type = pooling2d

[conv9/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 512
input_layers = conv8(0)
kernel_size = 3,3
name = conv9/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv9]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv9/a1(0)
momentum = 0.900000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv9
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv9/activation_realized]
activation = leaky_relu
input_layers = conv9(0)
name = conv9/activation_realized
trainable = true
type = activation

[conv10/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 256
input_layers = conv9/activation_realized(0)
kernel_size = 1,1
name = conv10/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv10]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv10/a1(0)
momentum = 0.900000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv10
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv10/activation_realized]
activation = leaky_relu
input_layers = conv10(0)
name = conv10/activation_realized
trainable = true
type = activation

[conv11/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 512
input_layers = conv10/activation_realized(0)
kernel_size = 3,3
name = conv11/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv11]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv11/a1(0)
momentum = 0.900000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv11
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv11/activation_realized]
activation = leaky_relu
input_layers = conv11(0)
name = conv11/activation_realized
trainable = true
type = activation

[conv12/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 256
input_layers = conv11/activation_realized(0)
kernel_size = 1,1
name = conv12/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv12]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv12/a1(0)
momentum = 0.900000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv12
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv12/activation_realized]
activation = leaky_relu
input_layers = conv12(0)
name = conv12/activation_realized
trainable = true
type = activation

[conv13/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 512
input_layers = conv12/activation_realized(0)
kernel_size = 3,3
name = conv13/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv13]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv13/a1(0)
momentum = 0.900000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv13
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv13/activation_realized]
activation = leaky_relu
input_layers = conv13(0)
name = conv13/activation_realized
trainable = true
type = activation

[conv13/generated_out_0]
input_layers = conv13/activation_realized(0)
name = conv13/generated_out_0
trainable = true
type = multiout

[conv_a_pool]
input_layers = conv13/generated_out_0(0)
name = conv_a_pool
padding = valid
pool_size = 2,2
pooling = max
stride = 2,2
trainable = true
type = pooling2d

[conv_a1/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 1024
input_layers = conv_a_pool(0)
kernel_size = 3,3
name = conv_a1/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv_a1]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv_a1/a1(0)
momentum = 0.900000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv_a1
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv_a1/activation_realized]
activation = leaky_relu
input_layers = conv_a1(0)
name = conv_a1/activation_realized
trainable = true
type = activation

[conv_a2/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 512
input_layers = conv_a1/activation_realized(0)
kernel_size = 1,1
name = conv_a2/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv_a2]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv_a2/a1(0)
momentum = 0.900000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv_a2
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv_a2/activation_realized]
activation = leaky_relu
input_layers = conv_a2(0)
name = conv_a2/activation_realized
trainable = true
type = activation

[conv_a3/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 1024
input_layers = conv_a2/activation_realized(0)
kernel_size = 3,3
name = conv_a3/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv_a3]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv_a3/a1(0)
momentum = 0.900000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv_a3
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv_a3/activation_realized]
activation = leaky_relu
input_layers = conv_a3(0)
name = conv_a3/activation_realized
trainable = true
type = activation

[conv_a4/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 512
input_layers = conv_a3/activation_realized(0)
kernel_size = 1,1
name = conv_a4/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv_a4]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv_a4/a1(0)
momentum = 0.900000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv_a4
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv_a4/activation_realized]
activation = leaky_relu
input_layers = conv_a4(0)
name = conv_a4/activation_realized
trainable = true
type = activation

[conv_a5/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 1024
input_layers = conv_a4/activation_realized(0)
kernel_size = 3,3
name = conv_a5/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv_a5]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv_a5/a1(0)
momentum = 0.900000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv_a5
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv_a5/activation_realized]
activation = leaky_relu
input_layers = conv_a5(0)
name = conv_a5/activation_realized
trainable = true
type = activation

[conv_a6/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 1024
input_layers = conv_a5/activation_realized(0)
kernel_size = 3,3
name = conv_a6/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv_a6]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv_a6/a1(0)
momentum = 0.900000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv_a6
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv_a6/activation_realized]
activation = leaky_relu
input_layers = conv_a6(0)
name = conv_a6/activation_realized
trainable = true
type = activation

[conv_a7/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 1024
input_layers = conv_a6/activation_realized(0)
kernel_size = 3,3
name = conv_a7/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv_a7]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv_a7/a1(0)
momentum = 0.900000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv_a7
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv_a7/activation_realized]
activation = leaky_relu
input_layers = conv_a7(0)
name = conv_a7/activation_realized
trainable = true
type = activation

[conv_b/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 64
input_layers = conv13/generated_out_0(1)
kernel_size = 1,1
name = conv_b/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv_b]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv_b/a1(0)
momentum = 0.900000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv_b
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv_b/activation_realized]
activation = leaky_relu
input_layers = conv_b(0)
name = conv_b/activation_realized
trainable = true
type = activation

[re_organization]
input_layers = conv_b/activation_realized(0)
name = re_organization
trainable = true
type = reorg_layer

[concat]
axis = 1
input_layers = conv_a7/activation_realized(0),re_organization(0)
name = concat
trainable = true
type = concat

[conv_out1/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 1024
input_layers = concat(0)
kernel_size = 3,3
name = conv_out1/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv_out1]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv_out1/a1(0)
momentum = 0.900000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv_out1
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv_out1/activation_realized]
activation = leaky_relu
input_layers = conv_out1(0)
name = conv_out1/activation_realized
trainable = true
type = activation

[conv_out2]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 45
input_layers = conv_out1/activation_realized(0)
kernel_size = 1,1
name = conv_out2
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[permute]
direction = 2,3,1
input_layers = conv_out2(0)
name = permute
trainable = true
type = permute

[reshape]
input_layers = permute(0)
name = reshape
target_shape = 1:169:5:9
trainable = true
type = reshape

[yolo_v2_loss]
class_number = 4
grid_height_number = 13
grid_width_number = 13
input_layers = reshape(0)
max_object_number = 4
name = yolo_v2_loss
trainable = true
type = yolo_v2_loss

